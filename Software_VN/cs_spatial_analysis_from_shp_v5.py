# -*- coding: utf-8 -*-
"""CS_Spatial_Analysis_from_shp_v5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cL-gHzKUGM78L8LDguJjovfTpggVMUQT
"""

!git clone https://github.com/CityScope/CSL_HCMC.git

!pip install --upgrade pip
!pip install --upgrade numpy

!pip install osmnet
!pip install cs-brix
!pip install matplotlib==3.1.3
!pip install osmnet
!pip install pandana
!pip install folium

import geopandas as gpd
import numpy as np
import matplotlib.pyplot as plt

"""# Read wards, POIs, buildings, house price and filter data for district 4"""

data_path = "CSL_HCMC/Data/GIS/"
pop_path = data_path + 'Population/population_HCMC/population_shapefile/'
wards = gpd.read_file(pop_path + 'Population_Ward_Level.shp')
districts = gpd.read_file(pop_path + 'Population_District_Level.shp')
dist4_wards = wards[wards['Dist_Name'] == 'District 4']

poi_path = data_path + 'POI/POI_model_area/Scenario{}/'
all_pois = {}
amenities = ['medical', 'park', 'education', 'commercial']

for i in [2, 3]:
  all_pois[i] = {'medical' : gpd.read_file(poi_path.format(i) + 'Merdical_{}.shp'.format(i)),
          'park' : gpd.read_file(poi_path.format(i) + 'GreeneryPark_{}.shp'.format(i)),
          'education' : gpd.read_file(poi_path.format(i) + 'Education_{}.shp'.format(i)),
          'commercial' : gpd.read_file(poi_path.format(i) + 'Commercial_Services_{}.shp'.format(i))}
i = 0
all_pois[i] = {'medical' : gpd.read_file(poi_path.format(i) + 'Merdical.shp'),
          'park' : gpd.read_file(poi_path.format(i) + 'GreeneryPark.shp'),
          'education' : gpd.read_file(poi_path.format(i) + 'Education.shp'),
          'commercial' : gpd.read_file(poi_path.format(i) + 'Commercial_Services.shp')}

all_buildings = {i: gpd.read_file(data_path + 'Scenario{}/Building_scenario_{}/calculating/Building_{}.shp'.format(i,i,i)) for i in [0, 3]}
all_buildings[2] = gpd.read_file(data_path + 'Scenario{}/Building_Scenario_{}/calculating/Building_{}.shp'.format(2,2,2))

dist4 = districts[districts['Dist_Name']=='District 4']
dist4_buildings = {idx : all_buildings[idx][all_buildings[idx].within(dist4.geometry.values[0])] for idx in [0, 2, 3]}

#all landuse
all_landuse = {i: gpd.read_file(data_path + 'Scenario{}/Landuse_scenario_{}/LandUse_{}.shp'.format(i,i,i)) for i in [0, 3]}
all_landuse[2] = gpd.read_file(data_path + 'Scenario{}/LandUse_Scenario_{}/LandUse_{}.shp'.format(2,2,2))

dist4_landuse = {idx : all_landuse[idx][all_landuse[idx].within(dist4.geometry.values[0])] for idx in [0, 2, 3]}

"""### Filter district areas in simulation boundary"""

from shapely.geometry import Polygon
sim_bound = all_buildings[0].total_bounds
sim_bound = Polygon([[sim_bound[0], sim_bound[3]], [sim_bound[0], sim_bound[1]], [sim_bound[2], sim_bound[1]], [sim_bound[2], sim_bound[3]]])

sim_districts = {i: districts[districts['Dist_Name']=='District {}'.format(i)] for i in [1, 2, 4, 7]}
sim_district_areas = {i: sim_districts[i].geometry.values[0].intersection(sim_bound).area for i in [1, 2, 4, 7]}

"""# Density Indicator

## Housing Density

Computer raw desity for each district
"""

sim_low_buildings = {}
sim_high_buildings = {}
sim_mix_buildings = {}

for dist_idx in [1, 2, 4, 7]:
  sim_low_buildings[dist_idx] = {}
  sim_high_buildings[dist_idx] = {}
  sim_mix_buildings[dist_idx] = {}
  for sim_idx in [0,2,3]:
    # Lay building trong district
    building_in_dist = all_buildings[sim_idx][all_buildings[sim_idx].within(sim_districts[dist_idx].geometry.values[0])]
    # Lay building low va high
    high_building = building_in_dist[building_in_dist['CSLLandTyp'] =='Residential - highrise']
    low_building = building_in_dist[building_in_dist['CSLLandTyp'] =='Residential - lowrise']
    mix_building = building_in_dist[building_in_dist['CSLLandTyp'] =='Mixed use']
    
    sim_low_buildings[dist_idx][sim_idx] = low_building
    sim_high_buildings[dist_idx][sim_idx] = high_building
    sim_mix_buildings[dist_idx][sim_idx] = mix_building

housing_density = {}
all_densities = []
for dist_idx in [1, 2, 4, 7]:
  housing_density[dist_idx] = {}
  for sim_idx in [0, 2, 3]:
    # So don vi o nha thap tang
    num_low = len(sim_low_buildings[dist_idx][sim_idx])

    # So don vi o nha cao tang 
    sim_high_buildings[dist_idx][sim_idx]['Shape_Area']
    num_high = sum(sim_high_buildings[dist_idx][sim_idx]['Shape_Area']*sim_high_buildings[dist_idx][sim_idx]['Storey'])/ 80
    
    # So don vi o cua khu Mixed-use
    num_mix_high = sum(sim_mix_buildings[dist_idx][sim_idx]['Shape_Area']*0.7*sim_mix_buildings[dist_idx][sim_idx]['Storey'])/ 80  #Dien tich de xay chung cu
    num_mix_low = sum(sim_mix_buildings[dist_idx][sim_idx]['Shape_Area']*0.3)/ 80  #Dien tich de xay nha pho
    housing_density[dist_idx][sim_idx] = (num_low + num_mix_low + num_high + num_mix_high)/ sim_district_areas[dist_idx]
    all_densities.append(housing_density[dist_idx][sim_idx])

housing_density

def normalise_indicator(raw_value, min_value, max_value):
    return (raw_value-min_value)/(max_value-min_value)

min_dens = min(all_densities)
print('Min density: ', min_dens)
max_dens = max(all_densities)
print('Max density: ', max_dens)

norm_housing_density = {}
for dist_idx in [1, 2, 4, 7]:
  norm_housing_density[dist_idx] = {}
  for sim_idx in [0, 2, 3]:
    norm_housing_density[dist_idx][sim_idx] = normalise_indicator(housing_density[dist_idx][sim_idx], min_dens, max_dens)
print('Housing density: ')
norm_housing_density

"""## Amenity Density"""

amenity_density = {}
all_amenity_densities = []

for dist_idx in [1, 2, 4, 7]:
  amenity_density[dist_idx] = {}
  for sim_idx in [0, 2, 3]:

    commercial_pois = all_pois[sim_idx]['commercial'][all_pois[sim_idx]['commercial']['District'] == 'District {}'.format(dist_idx)]
    education_pois = all_pois[sim_idx]['education'][all_pois[sim_idx]['education']['District'] == 'District {}'.format(dist_idx)]
    park_pois = all_pois[sim_idx]['park'][all_pois[sim_idx]['park']['District'] == 'District {}'.format(dist_idx)]
    medical_pois = all_pois[sim_idx]['medical'][all_pois[sim_idx]['medical']['District'] == 'District {}'.format(dist_idx)]

    amenity_density[dist_idx][sim_idx] = (len(commercial_pois) + len(education_pois) + len(park_pois) + len(medical_pois)) / sim_district_areas[dist_idx]
    all_amenity_densities.append(amenity_density[dist_idx][sim_idx])
all_amenity_densities

amenity_density

def normalise_indicator(raw_value, min_value, max_value):
    return (raw_value-min_value)/(max_value-min_value)

min_amenity_dens = min(all_amenity_densities)
print('Min amenity_density: ', min_amenity_dens)
max_amenity_dens = max(all_amenity_densities)
print('Max amenity_density: ', max_amenity_dens)

norm_amenity_density = {}
for dist_idx in [1, 2, 4, 7]:
  norm_amenity_density[dist_idx] = {}
  for sim_idx in [0, 2, 3]:
    norm_amenity_density[dist_idx][sim_idx] = normalise_indicator(amenity_density[dist_idx][sim_idx], min_amenity_dens, max_amenity_dens)
print('Amenity density: ')
norm_amenity_density

"""## Employment/Job Density"""

#compute full attributes of all districts
dist = {}
dist_full_attr_buildings = {}
dist_buildings = {}

for dist_idx in [1, 2, 4, 7]:
  dist_full_attr_buildings[dist_idx] = {}
  dist[dist_idx] = {}
  dist_buildings[dist_idx] = {}
  for sim_idx in [0, 2, 3]:
    print('Calculating full attributes for district {} in scenario {}'.format(dist_idx, sim_idx))
    dist[dist_idx][sim_idx] = districts[districts['Dist_Name']=='District {}'.format(dist_idx)]
    dist_buildings[dist_idx][sim_idx] = all_buildings[sim_idx][all_buildings[sim_idx].within(dist[dist_idx][sim_idx].geometry.values[0])]

    dist_full_attr_buildings[dist_idx][sim_idx] = dist_buildings[dist_idx][sim_idx].apply(lambda row: building_to_attributes(row, types), axis=1).fillna(0)

emp_density = {}
all_emp_densities = []

for dist_idx in [1, 2, 4, 7]:
  emp_density[dist_idx] = {}
  for sim_idx in [0, 2, 3]:
    print('Calculating density of emp for district {} in scenario {}'.format(dist_idx, sim_idx))
    
    #density follow MIT
    agg_site = dist_full_attr_buildings[dist_idx][sim_idx].sum(axis=0)
    emp_density[dist_idx][sim_idx] = agg_site['emp_total']/agg_site['Shape_Area']
    all_emp_densities.append(emp_density[dist_idx][sim_idx])
    print(emp_density[dist_idx][sim_idx])

min_emp_dens = min(all_emp_densities)
print('Min emp: ', min_emp_dens)
max_emp_dens = max(all_emp_densities)
print('Max emp: ', max_emp_dens)

norm_emp_density = {}
for dist_idx in [1, 2, 4, 7]:
  norm_emp_density[dist_idx] = {}
  for sim_idx in [0, 2, 3]:
    norm_emp_density[dist_idx][sim_idx] = normalise_indicator(emp_density[dist_idx][sim_idx], min_emp_dens, max_emp_dens)
print('Employment density: ')
norm_emp_density

"""# Diversity Indicator

## Housing Diversity
"""

import math
from scipy.spatial import cKDTree

def get_diversity(species_counts):
    num_species= len(species_counts)
    
    diversity=0
    pop_size=sum(species_counts) #mean what? total number of species
    # print(pop_size)
    if ((len(species_counts)>1) and (pop_size>0)):        
        for count in species_counts: #for each species in many species
            pj=count/pop_size #compute pj
            if not pj==0:
                diversity+= -pj*math.log(pj) #H
        equitability=diversity/math.log(len(species_counts)) #H per a one species
        return equitability
    else:
        return float('nan')

price_path = data_path + 'Price/building_price_shapefile/'
house_price = {idx: gpd.read_file(price_path + 'Building_Price_{}.shp'.format(idx)) for idx in [0, 2, 3]}

import pandas as pd

for sim_idx in [0, 2, 3]:
  for house_type in ['Residential - lowrise', 'Residential - highrise', 'Mixed use']:
    house_unk_price = house_price[sim_idx][(house_price[sim_idx].CSLLandTyp==house_type) & (house_price[sim_idx].Price==0)]
    ref_house_price = house_price[sim_idx][(house_price[sim_idx].CSLLandTyp==house_type) & (house_price[sim_idx].Price>0)]
    others = house_price[sim_idx][house_price[sim_idx].CSLLandTyp!=house_type]

    nA = np.array(list(house_unk_price.geometry.centroid.apply(lambda p: (p.x, p.y))))
    nB = np.array(list(ref_house_price.geometry.centroid.apply(lambda p: (p.x, p.y))))
    btree = cKDTree(nB)
    dist, idx = btree.query(nA, k=1)
    for loc in range(len(idx)):
      house_unk_price.Price.iloc[loc] = ref_house_price.Price.iloc[idx[loc]] * 0.6
    house_price[sim_idx] = pd.concat([house_unk_price, ref_house_price, others], axis=0)

def building_to_prices(row):
    total_building_price = row['Shape_Area_left']*row['Price'] #estimate total construction area of a building
    total_building_price += row['Storey']*row['Shape_Area_left']*row['BCR']/100.0*12.0
    row['townhouse_price']=total_building_price
    return row

def building_to_price_group(row, pranges):
    cat = -1
    left = 0
    for irate in range(len(pranges)):
      right = pranges[irate]
      if row['townhouse_price'] >= left and row['townhouse_price'] < right:
        cat = irate
      left = right
    if cat == -1:
      cat = len(pranges)
    row['price_group'] = cat
    return row

def apartment_to_price_group(row, pranges):
    ncats = np.array([0, 0, 0, 0])
    segments = np.array([40, 60, 90])
    rates = np.array([0.2, 0.7, 0.1])
    for idx, segment in enumerate(segments):
      price = row['Price'] * segment
      napart = row['Shape_Area_left'] * row['BCR']/100.0 * rates[idx] / segment
      #row['num_apart_{}'.format(segment)] = cat
      cat = -1
      left = 0
      for irate in range(len(pranges)):
        right = pranges[irate]
        #print(price, left, right)
        if price >= left and price < right:
          cat = irate
        left = right
      if cat == -1:
        cat = len(pranges)  
      ncats[cat] += napart
    
    for idx, ncat in enumerate(ncats):
      row['price_group_{}'.format(idx)] = ncat
    return row

from geopandas.tools import sjoin

housing_diversity = {4:{}}
for sim_idx in [0, 2, 3]:
  ranges = [3500, 7000, 9000]
  nhouses_pcat = []
  
  building_with_price = sjoin(dist4_buildings[sim_idx], house_price[sim_idx], how="left", op="within")
  low_buildings = building_with_price[building_with_price['CSLLandTyp_left']=='Residential - lowrise']
  high_buildings = building_with_price[building_with_price['CSLLandTyp_left']=='Residential - highrise']
  mixed_buildings = building_with_price[building_with_price['CSLLandTyp_left']=='Mixed use']
  
  # low-rise
  low_building_with_price = low_buildings.apply(lambda row: building_to_prices(row), axis=1).fillna(0)
  low_building_with_price = low_building_with_price.apply(lambda row: building_to_price_group(row, ranges), axis=1).fillna(0)
  
  nhouses_pcat.append(len(low_building_with_price[low_building_with_price['price_group']==0]))
  nhouses_pcat.append(len(low_building_with_price[low_building_with_price['price_group']==1]))
  nhouses_pcat.append(len(low_building_with_price[low_building_with_price['price_group']==2]))
  nhouses_pcat.append(len(low_building_with_price[low_building_with_price['price_group']==3]))
  
  # Mixed use
  mixed_buildings_with_cat = mixed_buildings.apply(lambda row: apartment_to_price_group(row, ranges), axis=1).fillna(0)

  agg_mixed_buildings = mixed_buildings_with_cat.sum()
  nhouses_pcat.append(0.7*agg_mixed_buildings['price_group_0'])
  nhouses_pcat.append(0.7*agg_mixed_buildings['price_group_1'])
  nhouses_pcat.append(0.7*agg_mixed_buildings['price_group_2'])
  nhouses_pcat.append(0.7*agg_mixed_buildings['price_group_3'])

  # High rise
  high_buildings_with_cat = high_buildings.apply(lambda row: apartment_to_price_group(row, ranges), axis=1).fillna(0)

  agg_high_buildings = high_buildings_with_cat.sum()
  if 'price_group_0' in agg_high_buildings:
    nhouses_pcat[-4] += agg_high_buildings['price_group_0']
    nhouses_pcat[-3] += agg_high_buildings['price_group_1']
    nhouses_pcat[-2] += agg_high_buildings['price_group_2']
    nhouses_pcat[-1] += agg_high_buildings['price_group_3']  
    
  housing_diversity[4][sim_idx] = get_diversity(nhouses_pcat)

nhouses_pcat

#OLD: housing_diversity
#{4: {0: 0.545877741592074, 2: 0.6353768963206002, 3: 0.6172825887486035}}
housing_diversity
#nhouses_pcat

housing_diversity = {}

for dist_idx in [1, 2, 4, 7]:
  housing_diversity[dist_idx] = {}
  for sim_idx in [0, 2, 3]:
    # So don vi o nha thap tang
    num_low = len(sim_low_buildings[dist_idx][sim_idx])

    # So don vi o nha cao tang 
    sim_high_buildings[dist_idx][sim_idx]['Shape_Area']
    num_high = sum(sim_high_buildings[dist_idx][sim_idx]['Shape_Area']*sim_high_buildings[dist_idx][sim_idx]['Storey'])/ 80
    
    # So don vi o cua khu Mixed-use
    num_mix_high = sum(sim_mix_buildings[dist_idx][sim_idx]['Shape_Area']*0.7*sim_mix_buildings[dist_idx][sim_idx]['Storey'])/ 80  #Dien tich de xay chung cu
    num_mix_low = sum(sim_mix_buildings[dist_idx][sim_idx]['Shape_Area']*0.3)/ 80  #Dien tich de xay nha pho
    housing_diversity[dist_idx][sim_idx] = get_diversity([num_low, num_mix_low, num_high + num_mix_high])

# Mount to save result
from google.colab import drive
drive.mount('/content/drive')
result_path = '/content/drive/MyDrive/3.Project/6.ARC-MIT/Result'

all_pois[0]['commercial']

"""## Amenity Diversity"""

amenity_diversity = {}

for dist_idx in [1, 2, 4, 7]:
  amenity_diversity[dist_idx] = {}
  for sim_idx in [0, 2, 3]:
    commercial_pois = all_pois[sim_idx]['commercial'][all_pois[sim_idx]['commercial']['District'] == 'District {}'.format(dist_idx)]
    education_pois = all_pois[sim_idx]['education'][all_pois[sim_idx]['education']['District'] == 'District {}'.format(dist_idx)]
    park_pois = all_pois[sim_idx]['park'][all_pois[sim_idx]['park']['District'] == 'District {}'.format(dist_idx)]
    medical_pois = all_pois[sim_idx]['medical'][all_pois[sim_idx]['medical']['District'] == 'District {}'.format(dist_idx)]

    amenity_diversity[dist_idx][sim_idx] = get_diversity([len(commercial_pois), len(education_pois), len(park_pois), len(medical_pois)])

amenity_diversity

"""## Employment/Job Diversity"""

industry_columns = {}
emp_diversity = {}

for dist_idx in [1, 2, 4, 7]:
  industry_columns[dist_idx] = {}
  emp_diversity[dist_idx] = {}
  for sim_idx in [0, 2, 3]:
    print('Calculating diversity of emp for district {} in scenario {}'.format(dist_idx, sim_idx))
    
    #diversity follow MIT
    industry_columns[dist_idx][sim_idx] = [col for col in dist_full_attr_buildings[dist_idx][sim_idx].columns if 'emp_naics' in col]

    agg_site = dist_full_attr_buildings[dist_idx][sim_idx].sum(axis=0)
    emp_diversity[dist_idx][sim_idx] = get_diversity([agg_site[col] for col in industry_columns[dist_idx][sim_idx]]) 
    print(emp_diversity[dist_idx][sim_idx])

"""# Live-Work Indicator"""

import pandas
landtypes = pandas.read_csv(data_path + '../Table/cslhcmc-landtype-v4.csv')
landtypes = landtypes.rename(columns ={'NAICS_proportions':'NAICS_proportion'})
landtypes.columns

def csv2json(typetable):
  types = {}
  for index in range(len(typetable)):
      #print(types[index])
      row = typetable[index:index+1]
      land_type = row['CSLLandtype'].values[0]
      types[land_type] = {}
      for attr in ['LBCS', 'NAICS']:
        types[land_type][attr] = {}
        codes = row[attr].values[0].split(', ')
        props = row[attr+'_proportion'].values[0].split(', ')
        sqm_pemp = row['Area per person (employee)\n(sqm/person)'].values[0].split(', ')
        sqm_pres = row['Area per person (resident)\n(sqm/person)'].values[0].split(', ')
        for idx, code in enumerate(codes):
          if code == 'Null':
            continue
          types[land_type][attr][code] = {}
          types[land_type][attr][code]['props'] = props[idx]
          if idx >= len(sqm_pemp):
            types[land_type][attr][code]['sqm_pemp'] = '0'
          else:
            types[land_type][attr][code]['sqm_pemp'] = sqm_pemp[idx]
          if idx >= len(sqm_pres):
            types[land_type][attr][code]['sqm_pres'] = '0'
          else:
            types[land_type][attr][code]['sqm_pres'] = sqm_pres[idx]
      
  return types

types = csv2json(landtypes)
types

def aggregate_area_attributes(attribute, total_area, type_info, digits=None): #compute capacity per each considered attribute
    """
    Takes as input the total capacity of a parcel/cell, the type description
    and an attributes of interest (eg. NAICS)
    Returns the total capacities associated with that attribute
    optionally reduce the precision of an attribute such as NAICS by supplying digits=n
    """
    aggregated={}
    # print("type info ", type_info)
    if attribute not in type_info:
        #print('attribute1', attribute)
        return aggregated
    if type_info[attribute] is not 'Null':
        for code in type_info[attribute]:
            if digits==None:
                code_digits=code
            else:
                code_digits=code[0:digits]
            #print(type_info[attribute][code]['sqm_pres'])
            sqm_pres = float(type_info[attribute][code]['sqm_pres'])
            if sqm_pres == 0:
              sqm_pres = np.inf
            sqm_pemp = float(type_info[attribute][code]['sqm_pemp'])
            if sqm_pemp == 0:
              sqm_pemp = np.inf

            attr_capacity = total_area*float(type_info[attribute][code]['props'])*(1/sqm_pres+1/sqm_pemp)
            #print('cap', attr_capacity)
            if code_digits in aggregated:
                aggregated[code_digits]+= attr_capacity
            else:
                aggregated[code_digits]= attr_capacity
    return aggregated

def building_to_attributes(row, types):
    name=row['CSLLandTyp']
    storeys=row['Storey']
    # print(storeys)
    type_info = types[name]
    
    total_area=storeys*row['Shape_Area'] #estimate total construction area of a building
    
    agg_naics=aggregate_area_attributes('NAICS', total_area, type_info, digits=2)
    
    agg_lbcs=aggregate_area_attributes('LBCS', total_area, type_info, digits=1)
    
    agg_res=aggregate_area_attributes('res_income', total_area, type_info, digits=None)
    
    for naics in agg_naics:
        row['emp_naics_{}'.format(naics)]=agg_naics[naics]   
    for res in agg_res:
        row['res_income{}'.format(res)]=agg_res[res]
    row['emp_total']=sum(agg_naics.values())
    
    if '1' in agg_lbcs:
        cell_population=agg_lbcs['1']
    else:
        cell_population=0
    row['res_total']=cell_population

    return row

live_work_scores = {} #building based
for sim_idx in [0, 2, 3]:
  print('Calculating for scenario ', sim_idx)
  dist4_full_attr_buildings = dist4_buildings[sim_idx].apply(lambda row: building_to_attributes(row, types), axis=1).fillna(0)
  agg_building = dist4_full_attr_buildings.sum(axis=0)
  live_work_scores[sim_idx] = agg_building['res_total']/agg_building['emp_total']
  if live_work_scores[sim_idx] > 1:
    live_work_scores[sim_idx] = 1/live_work_scores[sim_idx]

live_work_scores

live_work_scores_lu = {} #landuse based
dist4_full_attr_lu = {}
for sim_idx in [0, 2, 3]:
  print('Calculating for scenario ', sim_idx)
  dist4_full_attr_lu[sim_idx] = dist4_landuse[sim_idx].apply(lambda row: building_to_attributes(row, types), axis=1).fillna(0)
  agg_building = dist4_full_attr_lu[sim_idx].sum(axis=0)
  live_work_scores_lu[sim_idx] = agg_building['res_total']/agg_building['emp_total']
  if live_work_scores_lu[sim_idx] > 1:
    live_work_scores_lu[sim_idx] = 1/live_work_scores_lu[sim_idx]

live_work_scores_lu

"""#Accessibility"""

def compute_closest_distance(centroids, pois):
  distances = []
  for j in centroids:
    distances.append(np.min([j.distance(x) for x in pois['geometry']]))
  return distances

def compute_accessibility(centroids, pois, max_dist=500):
  accessibility = []
  circles = centroids.buffer(max_dist)
  for j in circles:
    accessibility.append(np.sum([j.contains(x) for x in pois['geometry']]))
  return accessibility

from brix import Indicator, Handler
from brix.examples import Diversity, RandomIndicator
import random

grids = {}
for idx in [0, 2, 3]:
  H = Handler('hcm_scenario_{}'.format(idx), quietly=False)
  geo_data = H.get_geogrid_data(include_geometries=True)
  grids[idx] = geo_data.as_df().to_crs('EPSG:32648')

Accessibilities = {}
num_pois = {}
for sim_idx in [0, 2, 3]:
  Accessibilities[sim_idx] = {}
  num_pois[sim_idx] = {}
  for amenity in amenities:
    print(amenity)
    pois = all_pois[sim_idx][amenity]
    num_pois[sim_idx][amenity] = len(pois)
    Accessibilities[sim_idx][amenity] = compute_accessibility(grids[sim_idx].centroid, pois)

import numpy as np
avg_accessibility = {}

for sim_idx in [0, 2, 3]:
  avg_accessibility[sim_idx] = {}

  for amenity in amenities:
      avg = np.average(Accessibilities[sim_idx][amenity])
      avg_accessibility[sim_idx][amenity] = avg
    
avg_accessibility
#  s0 {'commercial': 200.1969696969697,
#  'education': 5.704750204750205,
#  'medical': 2.6244881244881246,
#  'park': 0.2620802620802621}

for sim_idx in [0, 2, 3]:
    print("scenario: ", sim_idx)
    for amenity in amenities:
        fig, ax = plt.subplots(figsize=(16,7))
        plt.title('Accessibility heatmap for {} services within 500m'.format(amenity))
        plt.scatter(grids[idx].centroid.geometry.x, grids[idx].centroid.geometry.y, 
                    c=Accessibilities[sim_idx][amenity], s=32, cmap='YlOrRd')
        cb = plt.colorbar()
        plt.show()

"""# Mobility"""

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/CSL_HCMC/modules/"
!git clone https://github.com/CityScope/CS_Spatial_Modules.git

# use the Simulation class from the CS_Spatial_Modules submodule

import sys
sys.path.insert(0,'../modules/CS_Spatial_Modules')
import Simulation

all_zones=gpd.read_file('../outputs/zones.geojson').set_index('GEOID')

import pandana
import osmnet

bbox=all_zones.total_bounds
nodes_df,edges_df=osmnet.load.network_from_bbox(lat_min=bbox[1], lng_min=bbox[0], lat_max=bbox[3], 
                          lng_max=bbox[2], bbox=None, network_type='walk', 
                          two_way=True, timeout=180, 
                          custom_osm_filter=None)
nodes_df=nodes_df.rename(columns={'x': 'lon', 'y': 'lat'})

net=pandana.Network(nodes_df["lon"], nodes_df["lat"], edges_df["from"], edges_df["to"],
                 edges_df[["distance"]])

"""## MIT Proximity Indicator"""

# lu = dist4_landuse[0]
lu = dist4_full_attr_lu[0] #for each scenario, here is 0

lu=lu.to_crs('EPSG:4326')
centroids=lu.geometry.centroid
lu['x_centroid']=[c.x for c in centroids]
lu['y_centroid']=[c.y for c in centroids]

all_zones['copy_GEOID']=all_zones.index
zones_over_lu=gpd.overlay(all_zones, lu, 'intersection')
intersect_ids=zones_over_lu['copy_GEOID'].unique()
external_zones=all_zones.loc[[geoid for geoid in all_zones.index if geoid not in intersect_ids]]

intersect_ids

import matplotlib.pyplot as plt
fig, ax = plt.subplots(1,figsize=(10,10))
external_zones.plot(ax=ax, color='red')
lu.plot(ax=ax, color='blue')

# !pip uninstall geopandas
# !pip install pandas fiona shapely pyproj rtree
# !pip install geopandas

search_radius=1200 # roughly 15 minutes walking

"""#### Define the accessibility metrics we are interested in, their min and max values and the column which is used for weighting the results."""

prox_metrics={
    'Residential Access': {'column':'res_total','min': 0, 'max': 500000, 'from': 'emp_total'},
    'Employment Access': {'column':'emp_total','min': 0, 'max': 5000000, 'from': 'res_total'},
    'Education Access': {'column':'emp_naics_61','min': 0, 'max': 50000, 'from': 'res_total'},
    'Healthcare Access': {'column':'emp_naics_62','min': 0, 'max': 50000, 'from': 'res_total'}}

"""### First aggregate access to the external zones (from wards)"""

closest_node_ids_external = net.get_node_ids(x_col=external_zones['x_centroid'], y_col=external_zones['y_centroid'])

for name in prox_metrics:
    net.set(closest_node_ids_external, 
            variable=external_zones[prox_metrics[name]['column']], 
            name='{}_external'.format(name))

external_access={}
for name in prox_metrics:    
    external_access[name]=net.aggregate(distance=search_radius, type="sum", 
                        decay="linear", name='{}_external'.format(name),
                        imp_name='distance')

"""### Then aggregate access to the internal zones (from LU file)"""

closest_node_ids_internal = net.get_node_ids(x_col=lu['x_centroid'], y_col=lu['y_centroid'])

for name in prox_metrics:
    net.set(closest_node_ids_internal, 
            variable=lu[prox_metrics[name]['column']], 
            name='{}_internal'.format(name))

internal_access={}
for name in prox_metrics:    
    internal_access[name]=net.aggregate(distance=search_radius, type="sum", 
                        decay="linear", name='{}_internal'.format(name),
                        imp_name='distance')

"""### Add the access to external POIs to the acess to internal POIs to get the total access to each POI"""

overall_access={name: internal_access[name]+external_access[name] for name in internal_access}

"""#### Plot some of the results for illustration (Table area only)"""

internal_bbox=lu.total_bounds

table_node_ids=[ind for ind, n in nodes_df.iterrows() if (
    (n['lon']>internal_bbox[0]) and 
    (n['lon']<internal_bbox[2]) and 
    (n['lat']>internal_bbox[1]) and
    (n['lat']<internal_bbox[3]))]

def create_gdf_access(nodes_df, access_dict):
    nodes_gdf=gpd.GeoDataFrame(data=access_dict,geometry=gpd.points_from_xy(
        nodes_df['lon'], nodes_df['lat'], crs='EPSG:4326'))
    return nodes_gdf
    
def plot_gdf_access(gdf, to):
    fig, ax=plt.subplots(1, figsize=(12,10))
    gdf.plot(column=to, ax=ax, legend=True)

overall_access_table_only={x: overall_access[x][table_node_ids] for x in overall_access}

gdf_access=create_gdf_access(nodes_df.loc[table_node_ids],
                             overall_access_table_only)

"""Employment"""

plot_gdf_access(gdf_access, 'Employment Access')

"""Residential"""

plot_gdf_access(gdf_access, 'Residential Access')

np.array([overall_access_table_only[x] for x in overall_access_table_only]).T.shape

"""Create some different output formats for the access heatmaps"""

access_table=np.column_stack([nodes_df.loc[table_node_ids, ['lat', 'lon']], 
                              np.array([overall_access_table_only[x] for x in overall_access_table_only]).T])

import pandas as pd
access_table=pd.DataFrame(overall_access_table_only)
access_table=access_table.merge(nodes_df, left_index=True, right_index=True)
access_table

"""##### Save a geojson which is compatible with the access layer of CityScope_JS"""

access_var_list=overall_access.keys()
access_cs_js_format=gdf_access.copy().__geo_interface__
access_cs_js_format['properties']=list(access_var_list)
del(access_cs_js_format['bbox'])
for i_f, feat in enumerate(access_cs_js_format['features']):
    access_cs_js_format['features'][i_f]['properties']=[normalise_indicator(
        feat['properties'][var], prox_metrics[var]['min'], prox_metrics[var]['max']) for var in access_var_list]
    del(access_cs_js_format['features'][i_f]['bbox'])

"""## MIT Create a single access indicator for each POI

Compute a weighted average accross all nodes where each node is valued by the people coming to the POI from this node. For example, when computing accessibility to employment or amenities, we weight the accessibility at each node by how many people live at this node. For accessibility to residential, we weight by how many people work there. <br>
The 'from' variable for each access metric was already specified in the prox_metrics dictionary.<br>

A simple 'hack' to get the number of people employed/living at each node is to 'aggregate' with a search_radius of 1 meter. <br>

We can ignore the external zones for this
"""

sources={}
all_source_columns=set([prox_metrics[name]['from'] for name in prox_metrics])
all_source_columns
for column in all_source_columns:
    net.set(closest_node_ids_internal, 
            variable=lu[column], 
            name='{}_source'.format(column))
    sources[column]=net.aggregate(distance=1, type="sum", 
                        decay="linear", name='{}_source'.format(column),
                        imp_name='distance')

weighted_access={}
for name in prox_metrics:
    from_var=prox_metrics[name]['from']
    total_from=sources[from_var].sum()
    if total_from==0:
        weighted_access[name]=0
    else:
        weighted_access[name]=(overall_access[name].multiply(sources[from_var])).sum()/total_from

weighted_access

indicators = []
for name in weighted_access:
    indicators.append({
        'raw_value': weighted_access[name],
        'value': normalise_indicator(weighted_access[name], prox_metrics[name]['min'], prox_metrics[name]['max']),
        'name': name,
        'type': 'radar'    
})
indicators

"""## MIT Mobility Model

We will use the Simulation class from the CS_Spatial_Modules submodule
"""

import sys
sys.path.insert(0,'../modules/CS_Spatial_Modules')
import Simulation

lu=lu.set_index('OBJECTID')

combined_zones=external_zones.append(lu).fillna(0)
combined_zones.plot()

"""### Create zone to zone distance matrix"""

combined_zones['node']=net.get_node_ids(
                x_col=combined_zones['x_centroid'],y_col=combined_zones['y_centroid'])

"""Takes a few minutes:"""

zone_index=combined_zones.index
all_o_geoid=[]
for ind in zone_index:
    all_o_geoid.extend([ind]*len(zone_index))
all_d_geoid=list(zone_index)*len(zone_index)

all_o_nodes=combined_zones.loc[all_o_geoid,'node']
all_d_nodes=combined_zones.loc[all_d_geoid,'node']

all_dists=net.shortest_path_lengths(all_o_nodes,all_d_nodes, imp_name='distance')

all_dists_mat=np.reshape(all_dists, (len(zone_index), len(zone_index)))
dist_mat_df=pd.DataFrame(all_dists_mat)
dist_mat_df.columns=combined_zones.index
dist_mat_df.index=combined_zones.index

"""Replace zeros with a small distance to avid numerical issues"""

dist_mat_df=dist_mat_df.replace(0, 50)

dist_mat_df.head()

# dist_mat_df.to_csv('../outputs/dist_mat_s{}.csv'.format(s))

# dist_mat={}
# zone_index=combined_zones.index
# for o_ind in zone_index:
#     o_node=combined_zones.loc[o_ind]['node']
#     d_nodes=[combined_zones.loc[d_ind]['node'] for d_ind in zone_index]
#     dists=net.shortest_path_lengths([o_node]*len(d_nodes),d_nodes, imp_name='distance')
#     dists=[d if d>0 else 100 for d in dists ] # in case of same closest node
#     dist_mat[o_ind]={zone_index[d]: dists[d] for d in range(len(dists))}

# json.dump(dist_mat, open('../outputs/dist_mat_s{}'.format(s),'w'))
# dist_mat=json.load(open('../outputs/dist_mat_s{}'.format(s)))

"""### Create population based on land uses"""

import random
import numpy as np
import pandas as pd

def prob_floor(num):
    """
    Probabilistic "rounding" function
    eg. if num==1.2: this function will return 
    - 1.0 80% of the time 
    - 2.0 20% of the time
    """
    result=int(num)
    remainder=num-result
    if random.uniform(0, 1)<remainder:
        result+=1
    return result


def sample_home_locations(zones, work_geoid, dist_mat_df, n, beta=0.9):
    """ 
    Sample home locations using a simple gravity model.
    Attractiveness is proportional to the total residential capacity
    beta controls the distance decay
    """
    attraction=zones['res_total']
    impedance=[dist_mat_df.loc[hid,work_geoid] for hid in zones.index]
    weights=np.divide(attraction,np.power(impedance, beta))
    return np.random.choice(
        zones.index, replace=True, p=weights/sum(weights), size=n)

industry_columns=[col for col in lu.columns if 'emp_naics' in col]
res_income_columns=[col for col in lu.columns if 'res_income' in col]

def create_simpop(zones, sample_fraction=0.01):
    simpop=[]
    for geoid, row in zones.iterrows():
        for naics_col in industry_columns:
            naics_code=naics_col.split('emp_naics_')[1]
            capacity=row[naics_col]*sample_fraction
            n_workers=prob_floor(capacity)
            home_locations=sample_home_locations(zones, geoid, dist_mat_df, n_workers, beta=0.9)
            # TODO: age and income sampling should be weighted according to NAICS
            # i.e. people working in retail have a different age and income distribution to professionals
            earnings=np.random.choice(['1', '2', '3', '4'], replace=True,size=n_workers)
            age=np.random.choice(range(20,70), replace=True,size=n_workers)
            for i_w in range(n_workers):
                simpop.append({'work_geoid': geoid,'home_geoid': home_locations[i_w],
                                                   'naics': naics_code, 'earnings': earnings[i_w],
                                                  'age': age[i_w]})
    return simpop

simpop=create_simpop(combined_zones, sample_fraction=0.0001)
simpop_df=pd.DataFrame(simpop)

"""#### Only include people who either live OR work in the SIMULATION (table) area"""

print(len(simpop_df))
simpop_df=simpop_df.loc[((simpop_df['home_geoid'].isin(lu.index))|
                         (simpop_df['work_geoid'].isin(lu.index)))]
print(len(simpop_df))

simpop_df=simpop_df.sample(50)

"""### Load the mode choice model"""

import pickle
import json
mc_model=pickle.load(open('../outputs/mode_choice_model.p', 'rb'))
model_description=json.load(open('../outputs/mc_model_features.json'))

class Logistic_Mode_Choice_model():
    def __init__(self, mc_model, model_description):
        self.options=model_description['mode_order']
        self.features=model_description['features']
        self.dummy_map=model_description['dummy_map']
        self.model=mc_model
    
    def predict_modes(self, all_trips_df):
        data=all_trips_df.copy()
        for attr in self.dummy_map:
            dummys=pd.get_dummies(data[attr], prefix=self.dummy_map[attr])
            for col in dummys.columns:
                data[col]=dummys[col]
        for feat in self.features:
            if not feat in data.columns:
                print('{} not in data'.format(feat))
                data[feat]=0
        X=data[self.features]
        y_pred_proba=self.model.predict_proba(X)
        # Do all probabilistic samples with single call random number generator
        y_pred_proba_cum=np.cumsum(y_pred_proba, axis=1)
        p_cut=np.random.uniform(0, 1, len(data))
        y_pred=[self.options[np.argmax(y_pred_proba_cum[i]>p_cut[i])] for i in range(len(data))]
#         y_pred=[self.options[np.random.choice(range(len(y_pred_proba[i])), size=1, replace=True, p=y_pred_proba[i]
#                                 )[0]] for i in range(len(y_pred_proba))]
        all_trips_df['mode']=y_pred
        return all_trips_df

"""### Mode and profile descriptions"""

mode_colors=['#7fc97f',
'#beaed4',
'#fdc086',
'#ffff99',
'#386cb0',
'#f0027f',
'#bf5b17']

mode_descriptions=[{'name': model_description['mode_order'][i], 'color': mode_colors[i]
                  } for i in range(len(model_description['mode_order']))]

profile_descriptions = [{"name": '1',
                        'color': "#7fc97f"},
                         {"name": '2',
                        'color': "#beaed4"},
                         {"name": '3',
                        'color': "#fdc086"},
                        {"name": '4',
                        'color': "#ffff99"},
                        ]

"""### Create Mobility System

All modes use same network but with different average speeds
"""

edges_df['travel_time_drive']=edges_df['distance']/(50000/3600) # 50km/hr
edges_df['travel_time_walk']=edges_df['distance']/(5000/3600) # 5km/hr
edges_df['travel_time_cycle']=edges_df['distance']/(12000/3600) # 12km/hr

net=pandana.Network(nodes_df["lon"], nodes_df["lat"], edges_df["from"], edges_df["to"],
                 edges_df[["distance", "travel_time_drive", "travel_time_walk", "travel_time_cycle"]])

networks={}
networks['drive']=Simulation.PdnaNetwork(net)

mode_dicts={}
mode_dicts['Motorcycle']={'target_network_id': 'drive','travel_time_metric': 'travel_time_drive'}
mode_dicts['Bicycle']={'target_network_id': 'drive','travel_time_metric': 'travel_time_cycle'}
mode_dicts['Electric bicycle']={'target_network_id': 'drive','travel_time_metric': 'travel_time_cycle'}
mode_dicts['Walking']={'target_network_id': 'drive','travel_time_metric': 'travel_time_walk'}
mode_dicts['Bus']={'target_network_id': 'drive','travel_time_metric': 'travel_time_drive'}
mode_dicts['Car']={'target_network_id': 'drive','travel_time_metric': 'travel_time_drive'}
mode_dicts['Others']={'target_network_id': 'drive','travel_time_metric': 'travel_time_drive'}

modes={mode: Simulation.Mode(mode_dicts[mode]) for mode in mode_dicts}
mob_sys=Simulation.MobilitySystem(modes=modes, networks=networks)

sim=Simulation.Simulation(simpop_df, mob_sys, combined_zones, sim_geoids=lu.index,
            mode_descriptions=mode_descriptions, profile_descriptions=profile_descriptions)
sim.set_choice_models(mode_chooser=Logistic_Mode_Choice_model(mc_model, model_description))

"""### Run the Simulation"""

simpop_df=sim.create_simple_HWOWH_schedules(simpop_df)
all_trips_df=sim.create_trip_table(simpop_df)
all_trips_df['distance']=sim.mob_sys.networks['drive'].net.shortest_path_lengths(
    [n[0] for n in all_trips_df['from_possible_nodes_drive']],
    [n[0] for n in all_trips_df['to_possible_nodes_drive']],
    imp_name='distance')
all_trips_df=sim.mode_chooser.predict_modes(all_trips_df)
route_table=sim.get_routes_table(all_trips_df)
deckgl_trips=sim.routes_to_deckgl_trip(route_table)

"""#### Create additional outputs"""

route_gdf=sim.route_table_to_geo(route_table)
start_day_time_stamp=1626307200
trips_geo=sim.route_gdf_to_trips_geojson(route_gdf[['naics','earnings','age', 'mode', 'line_string', 'start_time', 'attributes', 'node_path']], 
                                         start_day_time_stamp=start_day_time_stamp)

"""#### Calculate a Mobility CO2 Indicator

Distances by mode (filtering out very large distances due to pandana failure to find route)
"""

distances_by_mode=route_table.loc[route_table['distance']<1e6].groupby('mode')['distance'].sum()
distances_by_mode

"""Values below are guesses- need to be replaced by estimates specific to Vietnam/HCMC"""

co2_kg_per_meter={'Motorcycle': 0.26/1000,
                 'Car': 0.27/1000,
                 'Electric bicycle': 0.1/1000,
                 'Bicycle': 0,
                 'Walking': 0,
                 'Bus': 0.2/1000,
                 'Others': 0.27/1000}

total_co2=sum([distances_by_mode[mode]*co2_kg_per_meter[mode] for mode in distances_by_mode.index])

co2_kg_per_person_day=total_co2/len(simpop_df)
co2_kg_per_person_day

"""Normalise the indicator- note that the min and max are flipped because smaller is better"""

co2_max=6
co2_min=2

co2_ind_norm = normalise_indicator(co2_kg_per_person_day, min_value=co2_max, max_value=co2_min)
1/co2_ind_norm

indicators.append({
        'raw_value': co2_kg_per_person_day,
        'value': co2_ind_norm,
        'name': 'Sustainable Mobility',
        'type': 'radar'    
})

indicators

#s0
print(co2_kg_per_person_day)
print(co2_ind_norm)
print(1/co2_ind_norm)

#s0: 1.5116852372000005
#s2: 1.7184060994000003
#s3: 1.5218902506

"""# Commit Density & Diversity, Live-work Score

"""

from brix import Indicator, Handler
from numpy import log
from collections import Counter

dist_idx_ref = 4
sim_idx_ref = 0

reference = {
    'Housing Density': norm_housing_density[dist_idx_ref][sim_idx_ref],
    'Amenity Density': norm_amenity_density[dist_idx_ref][sim_idx_ref],
    'Employment Density': norm_emp_density[dist_idx_ref][sim_idx_ref],
    'Housing Diversity': housing_diversity[dist_idx_ref][sim_idx_ref],
    'Amenity Diversity': amenity_diversity[dist_idx_ref][sim_idx_ref],
    'Employment Diversity': emp_diversity[dist_idx_ref][sim_idx_ref],
    'Live-Work Score': live_work_scores[dist_idx_ref][sim_idx_ref],
}

dist_idx = 4
sim_idx = 0

class HousingDensity(Indicator):
	def setup(self):
		self.name = 'Housing Density'
		self.requires_geogrid_props = False
		self.viz_type = 'radar'

	def return_indicator(self, geogrid_data):
		return norm_housing_density[dist_idx][sim_idx] #HousingDensity of Q4, s0

class AmenityDensity(Indicator):
	def setup(self):
		self.name = 'Amenity Density'
		self.requires_geogrid_props = False
		self.viz_type = 'radar'

	def return_indicator(self, geogrid_data):
		return norm_amenity_density[dist_idx][sim_idx] #AmenityDensity of Q4

class EmploymentDensity(Indicator):
	def setup(self):
		self.name = 'Employment Density'
		self.requires_geogrid_props = False
		self.viz_type = 'radar'

	def return_indicator(self, geogrid_data):
		return norm_emp_density[dist_idx][sim_idx] #HEmploymentDensity of Q4, s0

class HousingDiversity(Indicator):
	def setup(self):
		self.name = 'Housing Diversity'
		self.requires_geogrid_props = False
		self.viz_type = 'radar'

	def return_indicator(self, geogrid_data):
		return housing_diversity[dist_idx][sim_idx] #HousingDiversity of Q4, s0

class AmenityDiversity(Indicator):
	def setup(self):
		self.name = 'Amenity Diversity'
		self.requires_geogrid_props = False
		self.viz_type = 'radar'

	def return_indicator(self, geogrid_data):
		return amenity_diversity[dist_idx][sim_idx] #AmenityDiversity of Q4

class EmploymentDiversity(Indicator):
	def setup(self):
		self.name = 'Employment Diversity'
		self.requires_geogrid_props = False
		self.viz_type = 'radar'

	def return_indicator(self, geogrid_data):
		return emp_diversity[dist_idx][sim_idx] #EmploymentDiversity of Q4, s0

class LiveWorkScore(Indicator):
	def setup(self):
		self.name = 'Live-Work Score'
		self.requires_geogrid_props = False
		self.viz_type = 'radar'

	def return_indicator(self, geogrid_data):
		return live_work_scores[dist_idx][sim_idx] #live_work_score of Q4, s0

class Mobility(Indicator):
	def setup(self):
		self.name = 'Mobility'
		self.requires_geogrid_props = False
		self.viz_type = 'radar'

	def return_indicator(self, geogrid_data):
		return norm_mobility[dist_idx][sim_idx] #norm_mobility of Q4, s0

# H = Handler('hcm_scenario_0', reference=reference)
geogrid_data = H.get_geogrid_data()

housing_den = HousingDensity()
amenity_den = AmenityDensity()
employment_den = EmploymentDensity()
housing_div = HousingDiversity()
amenity_div = AmenityDiversity()
employment_div = EmploymentDiversity()
lw_score = LiveWorkScore()
mobility = Mobility()

H.add_indicator(housing_den)
H.add_indicator(amenity_den)
H.add_indicator(employment_den)
H.add_indicator(housing_div)
H.add_indicator(amenity_div)
H.add_indicator(employment_div)
H.add_indicator(lw_score)
H.add_indicator(mobility)

H.listen()

"""# Commit Static-Heatmap Accessibility"""

import numpy as np
from geopy.distance import distance as geodistance

class Accessibility(Indicator):
        def setup(self):
                self.name = 'Accessibility'
                self.indicator_type = 'heatmap'

        def return_indicator(self, geogrid_data):
                cells = [cell for cell in geogrid_data if cell['name'] != 'Water']
                features = []
                for index, cell in enumerate(cells):
                        cell_coords = list(np.mean(cell['geometry']['coordinates'][0],0) )
                        feature = {}
                        feature['geometry'] = {'coordinates': cell_coords,'type': 'Point'}
                        feature['properties'] = {'Park': float(Accessibilities['park'][cell['id']]) / max(Accessibilities['park']),
                                                 'Medical': float(Accessibilities['medical'][cell['id']]) / max(Accessibilities['medical']),
                                                 'Education': float(Accessibilities['education'][cell['id']]) / max(Accessibilities['education']),
                                                 'Commercial': float(Accessibilities['commercial'][cell['id']]) / max(Accessibilities['commercial'])}
                        features.append(feature)
                out = {'type':'FeatureCollection', 'features':features}
                return out

H = Handler('hcm_scenario_0') #link to a table
geogrid_data = H.get_geogrid_data()
A = Accessibility() 
H.add_indicator(A)
H.listen()







"""# (ignored) Install Libraries

In order to use pandana package, need to upgrade numpy
"""

!pip install osmnet
!pip install pandana
!pip install folium
!pip install matplotlib==3.1.3

# CityScope Brix
import brix

# Data analysis
import geopandas as gpd
import pandas as pd
import numpy as np

# Visualisations
import folium
import matplotlib.pyplot as plt

# osm and pandana
import osmnet
import pandana

"""### Initialise the brix handler for our CityScope table and plot the GEOGRIDDATA"""

import pandas as pd
import pandana as pdna
import matplotlib
from matplotlib import pyplot as plt

W_accesstoSM = {}
Acessibilities = {}
num_pois = {}
for amenity in amenities:
  pois = all_pois[amenity]
  num_pois[amenity] = len(pois)
  dists = compute_closest_distance(wards.centroid, pois)
  #W_accesstoSM[amenity] = 1.0/(ward_pops * dists)
  #accesstoSM_norm = w_acesstoSM / np.max(w_acesstoSM)
  Acessibilities[amenity] = compute_accessibility(wards.centroid, pois)



"""# (ignore) Accessibility Heatmap: number of POIs in a radius of 500m"""

def compute_closest_distance(centroids, pois):
  distances = []
  for j in centroids:
    distances.append(np.min([j.distance(x) for x in pois['geometry']]))
  return distances

def compute_accessibility(centroids, pois, max_dist=500):
  accessibility = []
  circles = centroids.buffer(max_dist)
  for j in circles:
    accessibility.append(np.sum([j.contains(x) for x in pois['geometry']]))
  return accessibility

_

"""Compute accessibility for POIs in building level"""

#idx = 0
#Acessibilities = {}
#num_pois = {}
#amenities = ['medical', 'park', 'education']
#for amenity in amenities:
#  print(amenity)
#  pois = all_pois[amenity]
#  num_pois[amenity] = len(pois)
#  Acessibilities[amenity] = compute_accessibility(dist4_buildings[idx].centroid, pois)

amenity = 'park'
fig, ax = plt.subplots(figsize=(15,7))
plt.title('Accessibility heatmap for Park services within 1000m')
plt.scatter(dist4_buildings[idx].centroid.geometry.x, dist4_buildings[idx].centroid.geometry.y, 
            c=Acessibilities[amenity], s=32, cmap='YlOrRd')

cb = plt.colorbar()
plt.show()

"""Compute accessibility for POIs in grid level"""

from brix import Indicator, Handler
from brix.examples import Diversity, RandomIndicator
import random

grids = {}
for idx in [0, 2, 3]:
  H = Handler('hcm_scenario_{}'.format(idx), quietly=False)
  geo_data = H.get_geogrid_data(include_geometries=True)
  grids[idx] = geo_data.as_df().to_crs('EPSG:32648')
  grids[idx] = grids[idx][grids[idx]['name']!='Water']

idx = 0
Acessibilities = {}
num_pois = {}
for amenity in amenities:
  print(amenity)
  pois = all_pois[amenity]
  num_pois[amenity] = len(pois)
  Acessibilities[amenity] = compute_accessibility(grids[idx].centroid, pois)
  Acessibilities[amenity] /= max(Acessibilities[amenity])

from brix import Indicator
import numpy as np
from geopy.distance import distance as geodistance

class Accessibility(Indicator):
        def setup(self):
                self.name = 'Accessibility'
                self.indicator_type = 'heatmap'

        def return_indicator(self,geogrid_data):
                #geogrid_data = geogrid_data[geogrid_data['name']!='Water']
                cells = [cell for cell in geogrid_data if cell['name']!='Water']
                features = []
                for i, cell in enumerate(cells):
                        cell_coords = list(np.mean(cell['geometry']['coordinates'][0],0) )
                        feature = {}
                        feature['geometry'] = {'coordinates': cell_coords,'type': 'Point'}
                        feature['properties'] = {"Park": float(Acessibilities['park'][i]), 
                                                 "Medical": float(Acessibilities['medical'][i]),
                                                 "Education": float(Acessibilities['education'][i]),
                                                 "Commercial": float(Acessibilities['commercial'][i])}
                        features.append(feature)

                out = {'type':'FeatureCollection','features':features}
                return out


H = Handler('hcm_scenario_0', quietly=False)
PA = Accessibility()
H.add_indicators([PA])
H.listen()

np.average(Acessibilities['education'])

amenity = 'park'
fig, ax = plt.subplots(figsize=(16,7))
plt.title('Accessibility heatmap for Park services within 500m')
plt.scatter(grids[idx].centroid.geometry.x, grids[idx].centroid.geometry.y, 
            c=Acessibilities[amenity], s=32, cmap='YlOrRd')

cb = plt.colorbar()
plt.show()

amenity = 'commercial'
fig, ax = plt.subplots(figsize=(16,7))
plt.title('Accessibility heatmap for Commercial services within 500m')
plt.scatter(grids[idx].centroid.geometry.x, grids[idx].centroid.geometry.y, 
            c=Acessibilities[amenity], s=32, cmap='YlOrRd')

cb = plt.colorbar()
plt.show()

amenity = 'medical'
fig, ax = plt.subplots(figsize=(16,7))
plt.title('Accessibility heatmap for Medical services within 500m')
plt.scatter(grids[idx].centroid.geometry.x, grids[idx].centroid.geometry.y, 
            c=Acessibilities[amenity], s=32, cmap='YlOrRd')

cb = plt.colorbar()
plt.show()

amenity = 'education'
fig, ax = plt.subplots(figsize=(16,7))
plt.title('Accessibility heatmap for Education services within 500m')
plt.scatter(grids[idx].centroid.geometry.x, grids[idx].centroid.geometry.y, 
            c=Acessibilities[amenity], s=32, cmap='YlOrRd')

cb = plt.colorbar()
plt.show()